{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar namesDataset"
      ],
      "metadata": {
        "id": "kCPe38Eg-SEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install names-dataset"
      ],
      "metadata": {
        "id": "rEBjXQ1_9xjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesado datos del INE\n"
      ],
      "metadata": {
        "id": "-txWNV5z9585"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files, drive\n",
        "import io\n",
        "\n",
        "excel_file_path = \"nombres_mas_frecuentes.xlsx\"\n",
        "nombre_archivo = excel_file_path\n",
        "sheet_name = 3\n",
        "\n",
        "df_full = pd.read_excel(\n",
        "    nombre_archivo,\n",
        "    sheet_name=sheet_name,\n",
        "    header=None\n",
        ")\n",
        "\n",
        "provinces_series_raw = df_full.iloc[2]\n",
        "provinces_series_filled = provinces_series_raw.ffill()\n",
        "\n",
        "df_data = pd.read_excel(\n",
        "    nombre_archivo,\n",
        "    sheet_name=sheet_name,\n",
        "    header=3\n",
        ")\n",
        "\n",
        "dfs_list = []\n",
        "\n",
        "for i in range(1, len(df_data.columns),3):\n",
        "    temp_df = df_data.iloc[:, i:i+3].copy()\n",
        "\n",
        "    if temp_df.shape[1] == 3:\n",
        "        province = df_data.columns[i]\n",
        "        temp_df.columns = ['Nombre', 'Frecuencia', 'Por 1.000']\n",
        "\n",
        "        temp_df['Provincia'] = province\n",
        "\n",
        "        dfs_list.append(temp_df)\n",
        "\n",
        "nombres_hombres = pd.concat(dfs_list, ignore_index=True)\n",
        "nombres_hombres.dropna(subset=['Nombre'], inplace=True)\n",
        "nombres_hombres = nombres_hombres[nombres_hombres['Nombre'] != 'NOMBRE']\n",
        "nombres_hombres.reset_index(drop=True, inplace=True)\n",
        "\n",
        "nombres_hombres['Frecuencia'] = pd.to_numeric(nombres_hombres['Frecuencia'], errors='coerce')\n",
        "nombres_hombres['Por 1.000'] = pd.to_numeric(nombres_hombres['Por 1.000'], errors='coerce')\n",
        "\n",
        "nombres_hombres['Provincia'] = nombres_hombres['Provincia'].astype(str)\n",
        "\n",
        "print(\"\\nDataFrame final reestructurado (primeras filas):\")\n",
        "print(nombres_hombres.head())\n",
        "print(\"\\nNúmero de filas en el DataFrame final:\", len(nombres_hombres))"
      ],
      "metadata": {
        "id": "QILI2UUR-Jxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files, drive\n",
        "import io\n",
        "\n",
        "excel_file_path = \"nombres_mas_frecuentes.xlsx\"\n",
        "nombre_archivo = excel_file_path\n",
        "sheet_name = 4\n",
        "\n",
        "df_full = pd.read_excel(\n",
        "    nombre_archivo,\n",
        "    sheet_name=sheet_name,\n",
        "    header=None\n",
        ")\n",
        "\n",
        "provinces_series_raw = df_full.iloc[2]\n",
        "provinces_series_filled = provinces_series_raw.ffill()\n",
        "\n",
        "df_data = pd.read_excel(\n",
        "    nombre_archivo,\n",
        "    sheet_name=sheet_name,\n",
        "    header=3\n",
        ")\n",
        "\n",
        "dfs_list = []\n",
        "\n",
        "for i in range(1, len(df_data.columns),3):\n",
        "    temp_df = df_data.iloc[:, i:i+3].copy()\n",
        "\n",
        "    if temp_df.shape[1] == 3:\n",
        "        province = df_data.columns[i]\n",
        "        temp_df.columns = ['Nombre', 'Frecuencia', 'Por 1.000']\n",
        "\n",
        "        temp_df['Provincia'] = province\n",
        "\n",
        "        dfs_list.append(temp_df)\n",
        "\n",
        "nombres_mujeres = pd.concat(dfs_list, ignore_index=True)\n",
        "nombres_mujeres.dropna(subset=['Nombre'], inplace=True)\n",
        "nombres_mujeres = nombres_mujeres[nombres_mujeres['Nombre'] != 'NOMBRE']\n",
        "nombres_mujeres.reset_index(drop=True, inplace=True)\n",
        "\n",
        "nombres_mujeres['Frecuencia'] = pd.to_numeric(nombres_mujeres['Frecuencia'], errors='coerce')\n",
        "nombres_mujeres['Por 1.000'] = pd.to_numeric(nombres_mujeres['Por 1.000'], errors='coerce')\n",
        "\n",
        "nombres_mujeres['Provincia'] = nombres_mujeres['Provincia'].astype(str)\n",
        "\n",
        "print(\"\\nDataFrame final reestructurado (primeras filas):\")\n",
        "print(nombres_mujeres.head())\n",
        "print(\"\\nNúmero de filas en el DataFrame final:\", len(nombres_mujeres))"
      ],
      "metadata": {
        "id": "qrdzGNgx-GTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nombres_comunidad = pd.concat([nombres_hombres, nombres_mujeres], ignore_index=True)\n",
        "nombres_comunidad"
      ],
      "metadata": {
        "id": "Z0PJFoVM95u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files, drive\n",
        "import io\n",
        "\n",
        "excel_file_path = \"apellidos_mas_frecuentes.xls\"\n",
        "nombre_archivo = excel_file_path\n",
        "sheet_name = 2\n",
        "\n",
        "df_full = pd.read_excel(\n",
        "    nombre_archivo,\n",
        "    sheet_name=sheet_name,\n",
        "    header=None\n",
        ")\n",
        "\n",
        "provinces_series_raw = df_full.iloc[2]\n",
        "provinces_series_filled = provinces_series_raw.ffill()\n",
        "\n",
        "df_data = pd.read_excel(\n",
        "    nombre_archivo,\n",
        "    sheet_name=sheet_name,\n",
        "    header=3\n",
        ")\n",
        "\n",
        "dfs_list = []\n",
        "\n",
        "for i in range(1, len(df_data.columns),3):\n",
        "    temp_df = df_data.iloc[:, i:i+3].copy()\n",
        "\n",
        "    if temp_df.shape[1] == 3:\n",
        "        province = df_data.columns[i]\n",
        "        temp_df.columns = ['Apellido', 'Frecuencia', 'Por 1.000']\n",
        "\n",
        "        temp_df['Provincia'] = province\n",
        "\n",
        "        dfs_list.append(temp_df)\n",
        "\n",
        "apellidos = pd.concat(dfs_list, ignore_index=True)\n",
        "apellidos.dropna(subset=['Apellido'], inplace=True)\n",
        "apellidos = apellidos[apellidos['Apellido'] != 'PRIMER APELLIDO']\n",
        "apellidos.reset_index(drop=True, inplace=True)\n",
        "\n",
        "apellidos['Frecuencia'] = pd.to_numeric(apellidos['Frecuencia'], errors='coerce')\n",
        "apellidos['Por 1.000'] = pd.to_numeric(apellidos['Por 1.000'], errors='coerce')\n",
        "\n",
        "apellidos['Provincia'] = apellidos['Provincia'].astype(str)\n",
        "\n",
        "print(\"\\nDataFrame final reestructurado (primeras filas):\")\n",
        "print(apellidos.head())\n",
        "print(\"\\nNúmero de filas en el DataFrame final:\", len(apellidos))"
      ],
      "metadata": {
        "id": "TmUA1wRv9x7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictor"
      ],
      "metadata": {
        "id": "SWqm5AxY-Pb3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu2iqGn99peu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from names_dataset import NameDataset\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "def get_most_probable_country(scores_dict):\n",
        "    \"\"\"Dado un diccionario de {pais: puntuacion}, retorna el país con la puntuación más alta.\"\"\"\n",
        "    filtered_scores = {k: v for k, v in scores_dict.items() if v > 0}\n",
        "    if not filtered_scores:\n",
        "        return \"Desconocido\"\n",
        "    try:\n",
        "        most_probable = max(filtered_scores, key=filtered_scores.get)\n",
        "        return most_probable\n",
        "    except ValueError:\n",
        "        return \"Desconocido\"\n",
        "\n",
        "def predict_autonomous_community(first_name, df_comunidad):\n",
        "    \"\"\"\n",
        "    Predice la Comunidad Autónoma probable basada en el nombre de pila y el género,\n",
        "    usando los datos del INE.\n",
        "    \"\"\"\n",
        "\n",
        "    nombre_filtered_df = df_comunidad[df_comunidad['Nombre'].str.upper() == first_name.upper()]\n",
        "\n",
        "    if nombre_filtered_df.empty:\n",
        "        return \"Desconocido (Nombre no encontrado en INE)\"\n",
        "\n",
        "    community_scores = defaultdict(float)\n",
        "    for index, row in nombre_filtered_df.iterrows():\n",
        "        provincia_str = row['Provincia']\n",
        "        score_por_mil = row['Por 1.000']\n",
        "\n",
        "        if not pd.isna(score_por_mil):\n",
        "             community_scores[provincia_str] += score_por_mil\n",
        "        else:\n",
        "             print(f\"Advertencia: Score NaN para '{first_name}' en '{provincia_str}'. Saltando.\")\n",
        "\n",
        "\n",
        "    return get_most_probable_country(community_scores)\n",
        "\n",
        "def predict_autonomous_community_surname(surname, df_comunidad):\n",
        "    \"\"\"\n",
        "    Predice la Comunidad Autónoma probable basada en el nombre de pila y el género,\n",
        "    usando los datos del INE.\n",
        "    \"\"\"\n",
        "\n",
        "    nombre_filtered_df = df_comunidad[df_comunidad['Apellido'].str.upper() == surname.upper()]\n",
        "\n",
        "    if nombre_filtered_df.empty:\n",
        "        return \"Desconocido (Apellido no encontrado en INE)\"\n",
        "\n",
        "    community_scores = defaultdict(float)\n",
        "    for index, row in nombre_filtered_df.iterrows():\n",
        "        provincia_str = row['Provincia']\n",
        "        score_por_mil = row['Por 1.000']\n",
        "\n",
        "        if not pd.isna(score_por_mil):\n",
        "             community_scores[provincia_str] += score_por_mil\n",
        "        else:\n",
        "             print(f\"Advertencia: Score NaN para '{surname}' en '{provincia_str}'. Saltando.\")\n",
        "\n",
        "\n",
        "    return get_most_probable_country(community_scores)\n",
        "\n",
        "\n",
        "def parse_name_parts(full_name):\n",
        "    \"\"\"\n",
        "    Intenta dividir un nombre completo en nombre(s) de pila y apellidos(s)\n",
        "    basándose en una heurística simple.\n",
        "    Puede necesitar ajustes para diferentes convenciones.\n",
        "    \"\"\"\n",
        "    parts = full_name.strip().split()\n",
        "    num_parts = len(parts)\n",
        "\n",
        "    if num_parts == 0:\n",
        "        return None, None, None\n",
        "\n",
        "    nombre = parts[0]\n",
        "    apellido1 = None\n",
        "    apellido2 = None\n",
        "\n",
        "    if num_parts == 1:\n",
        "        pass\n",
        "    elif num_parts == 2:\n",
        "        apellido1 = parts[1]\n",
        "    elif num_parts == 3:\n",
        "        nombre = parts[0]\n",
        "        apellido1 = parts[1]\n",
        "        apellido2 = parts[2]\n",
        "    else:\n",
        "        pos = 0\n",
        "        nombre_completo = [\"\", \"\", \"\"]\n",
        "        parts.reverse()\n",
        "        for part in range(0, num_parts):\n",
        "            if len(parts[part]) > 3:\n",
        "              if nombre_completo[pos] == \"\":\n",
        "                nombre_completo[pos] = parts[part]\n",
        "                pos += 1\n",
        "              else:\n",
        "                nombre_completo[pos] = nombre_completo[pos] + \" \" + parts[part]\n",
        "            elif len(parts[part]) <= 3:\n",
        "                nombre_completo[pos - 1] = parts[part] + \" \" + nombre_completo[pos - 1]\n",
        "            if pos >= 2:\n",
        "              pos = 2\n",
        "        apellido2 = nombre_completo[0]\n",
        "        apellido1 = nombre_completo[1]\n",
        "        nombre = nombre_completo[2]\n",
        "        print(f\"Nombre: {nombre}; Primer apellido: {apellido1}; Segundo apellido: {apellido2}\")\n",
        "\n",
        "\n",
        "    print(f\"Nombre: {nombre}; Primer apellido: {apellido1}; Segundo apellido: {apellido2}\")\n",
        "    return nombre, apellido1, apellido2\n",
        "\n",
        "\n",
        "def process_customer_name_improved(nd_instance, full_name):\n",
        "    \"\"\"\n",
        "    Procesa una cadena de nombre completo usando parsing mejorado\n",
        "    y combinación de puntuaciones ponderada.\n",
        "    \"\"\"\n",
        "    if not isinstance(full_name, str) or not full_name.strip():\n",
        "        return \"Desconocido\", \"Desconocido\", \"Desconocido\", \"Desconocido\"\n",
        "\n",
        "    cleaned_name = full_name.strip()\n",
        "\n",
        "    nombre, apellido1, apellido2 = parse_name_parts(cleaned_name)\n",
        "\n",
        "    weight_nombre = 0.3\n",
        "    weight_apellido1 = 0.4\n",
        "    weight_apellido2 = 0.3\n",
        "\n",
        "    scores_nombre = {}\n",
        "    scores_s1 = {}\n",
        "    scores_s2 = {}\n",
        "\n",
        "    pais_nombre_probable = \"Desconocido\"\n",
        "    if nombre:\n",
        "        try:\n",
        "            search_result = nd_instance.search(nombre)\n",
        "            if 'first_name' in search_result and 'country' in search_result['first_name']:\n",
        "                scores_nombre = search_result['first_name']['country']\n",
        "\n",
        "            pais_nombre_probable = get_most_probable_country(scores_nombre)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "\n",
        "    pais_s1_probable = \"Desconocido\"\n",
        "    if apellido1:\n",
        "        try:\n",
        "            search_result = nd_instance.search(apellido1)\n",
        "            if 'last_name' in search_result and 'country' in search_result['last_name']:\n",
        "                 scores_s1 = search_result['last_name']['country']\n",
        "            pais_s1_probable = get_most_probable_country(scores_s1)\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    pais_s2_probable = \"Desconocido\"\n",
        "    if apellido2:\n",
        "          try:\n",
        "            search_result = nd_instance.search(apellido2)\n",
        "            if 'last_name' in search_result and 'country' in search_result['last_name']:\n",
        "                 scores_s2 = search_result['last_name']['country']\n",
        "            pais_s2_probable = get_most_probable_country(scores_s2)\n",
        "          except Exception as e:\n",
        "            pass\n",
        "\n",
        "    combined_scores = defaultdict(float)\n",
        "\n",
        "    if scores_nombre:\n",
        "        for country, score in scores_nombre.items():\n",
        "            combined_scores[country] += score * weight_nombre\n",
        "\n",
        "    if scores_s1:\n",
        "        for country, score in scores_s1.items():\n",
        "            combined_scores[country] += score * weight_apellido1\n",
        "\n",
        "    if scores_s2:\n",
        "        for country, score in scores_s2.items():\n",
        "            combined_scores[country] += score * weight_apellido2\n",
        "\n",
        "    pais_final_probable = get_most_probable_country(combined_scores)\n",
        "\n",
        "    return pais_nombre_probable, pais_s1_probable, pais_s2_probable, pais_final_probable\n",
        "\n",
        "\n",
        "print(\"Inicializando NamesDataset. Esto puede tardar un poco la primera vez...\")\n",
        "try:\n",
        "    from names_dataset import NameDataset\n",
        "    nd = NameDataset()\n",
        "    print(\"NamesDataset inicializado correctamente.\")\n",
        "except ImportError:\n",
        "    try:\n",
        "        from names_dataset import NamesDataset\n",
        "        nd = NamesDataset()\n",
        "        print(\"NamesDataset inicializado correctamente (importación alternativa).\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fatal al inicializar NamesDataset: {e}\")\n",
        "        print(\"Por favor, asegúrate de que la librería 'names-dataset' está instalada correctamente.\")\n",
        "        exit()\n",
        "\n",
        "\n",
        "archivo_clientes = 'Clientes_Tienda.xlsx'\n",
        "columna_razon_social = 'Razón social'\n",
        "\n",
        "try:\n",
        "    df = pd.read_excel(archivo_clientes)\n",
        "\n",
        "    if columna_razon_social not in df.columns:\n",
        "        raise ValueError(f\"La columna '{columna_razon_social}' no se encontró en el archivo.\")\n",
        "\n",
        "    print(f\"Dataset '{archivo_clientes}' cargado correctamente. Filas encontradas: {len(df)}\")\n",
        "    print(f\"Utilizando la columna '{columna_razon_social}' para extraer nombres.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Archivo '{archivo_clientes}' no encontrado. Por favor, verifica la ruta.\")\n",
        "    exit()\n",
        "except ValueError as ve:\n",
        "     print(f\"Error en el dataset: {ve}\")\n",
        "     exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error al cargar el dataset: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "paises_nombre_list = []\n",
        "paises_s1_list = []\n",
        "paises_s2_list = []\n",
        "paises_final_list = []\n",
        "\n",
        "print(\"Procesando clientes para determinar países probables...\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    full_name = row[columna_razon_social]\n",
        "\n",
        "    pais_nombre, pais_s1, pais_s2, pais_final = process_customer_name_improved(nd, full_name)\n",
        "    name_parts = full_name.strip().split()\n",
        "    spain = 0\n",
        "\n",
        "    comunidad_probable = predict_autonomous_community(\n",
        "        full_name.strip().split()[0],\n",
        "        nombres_comunidad\n",
        "    )\n",
        "    if comunidad_probable == 'Desconocido (Nombre no encontrado en INE)':\n",
        "          comunidad_probable = pais_nombre\n",
        "    else:\n",
        "      spain += 1\n",
        "\n",
        "    comunidad_probable2 = predict_autonomous_community_surname(full_name.strip().split()[1], apellidos)\n",
        "    if comunidad_probable2 == 'Desconocido (Apellido no encontrado en INE)':\n",
        "      comunidad_probable2 = pais_s1\n",
        "    else:\n",
        "      spain += 1\n",
        "\n",
        "    comunidad_probable3 = pais_s2\n",
        "    if len(name_parts) > 2:\n",
        "        comunidad_probable3 = predict_autonomous_community_surname(name_parts[2], apellidos)\n",
        "        if comunidad_probable3 == 'Desconocido (Apellido no encontrado en INE)':\n",
        "            comunidad_probable3 = pais_s2\n",
        "        else:\n",
        "          spain += 1\n",
        "\n",
        "\n",
        "    paises_nombre_list.append(comunidad_probable)\n",
        "    paises_s1_list.append(comunidad_probable2)\n",
        "    paises_s2_list.append(comunidad_probable3)\n",
        "    if spain >= 2:\n",
        "      paises_final_list.append('Spain')\n",
        "    else:\n",
        "      paises_final_list.append(pais_final)\n",
        "\n",
        "    if (index + 1) % 100 == 0:\n",
        "        print(f\"--- {index + 1} clientes procesados ---\")\n",
        "\n",
        "print(\"Procesamiento de clientes completado.\")\n",
        "\n",
        "df['País Nombre Probable'] = paises_nombre_list\n",
        "df['País 1er Apellido Probable'] = paises_s1_list\n",
        "df['País 2do Apellido Probable'] = paises_s2_list\n",
        "df['País Final Probable'] = paises_final_list\n",
        "\n",
        "print(\"\\n--- DataFrame con países probables (primeras filas) ---\")\n",
        "columnas_a_mostrar = [columna_razon_social, 'País Nombre Probable', 'País 1er Apellido Probable', 'País 2do Apellido Probable', 'País Final Probable']\n",
        "print(df[columnas_a_mostrar].head())\n",
        "\n",
        "ruta_guardar = 'clientes_con_pais_probable.csv'\n",
        "df.to_csv(ruta_guardar, index=False)\n",
        "print(f\"\\nDataFrame actualizado guardado en '{ruta_guardar}'\")"
      ]
    }
  ]
}